# Readme
"""
–ü–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω—ã–π –ø–∞—Ä—Å–µ—Ä —Å–∞–π—Ç–∞ –∫–∞—Ñ–µ–¥—Ä—ã –°–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –°–ü–±–ì–£ (2007‚Äì2024).
‚Äî –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –∫—É–∫–∏
‚Äî –ñ–¥—ë—Ç –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–∞–±–æ—Ç –≤ #ThesisList
‚Äî –î–ª—è –∫–∞–∂–¥–æ–π —Ä–∞–±–æ—Ç—ã –±–µ—Ä—ë—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–≤–Ω—É—Ç—Ä–∏ –≥–æ–¥ + —Ç–µ–º–∞ –¥–∏–ø–ª–æ–º–∞), —Å—Å—ã–ª–∫—É –Ω–∞ PDF –ø–æ XPath
‚Äî –°–∫–∞—á–∏–≤–∞–µ—Ç pdf –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –º–æ–¥—É–ª–µ process_pdf.py
‚Äî –ú–µ–Ω—è–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É –≤ url.
"""

import time
from pathlib import Path
import requests
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from parser_pdf import parse
import json
import hashlib
import traceback
from selenium.common.exceptions import TimeoutException, WebDriverException

BASE = "https://se.math.spbu.ru"
PARAMS = "search=&supervisor=0&course=0&startdate=2007&enddate=2022&worktype=1"
URL = f"{BASE}/theses.html?{PARAMS}"
HEAD = {"User-Agent": "Mozilla/5.0"}

# –∫—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å json –∏ pdf (–Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ pdf —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∏ –æ—Ç–ª–∞–¥–∫–∏)
OUT = Path("downloads")


def download(session, href: str, title: str, topic: str):
    """
    –°–∫–∞—á–∏–≤–∞–µ–º pdf (–µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç) –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º (–µ—Å–ª–∏ –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–ª–∏) –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –º–æ–¥—É–ª–µ.
    """
    OUT.mkdir(exist_ok=True)

    id = href[href.find('=')+1:]
    fn = OUT/f"{get_md5_hash(title)}.pdf"
    fnj = OUT/f"{get_md5_hash(title)}.json"

    if fnj.exists():
        print(f"[‚úì] –£–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {fn.name}")
        return
    if fn.exists():
        print(f"[.] –£–∂–µ —Å–∫–∞—á–∞–Ω, –æ–±—Ä–∞–±–æ—Ç–∞–µ–º: {fn.name}")
        process_pdf(fn, title, topic, id)
        return

    print(f"[‚Üì] {title}")
    r = session.get(href, stream=True, headers=HEAD, timeout=30)
    r.raise_for_status()

    with open(fn, "wb") as f:
        for c in r.iter_content(8192):
            f.write(c)
    print(f"[+] –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {fn.name}")

    process_pdf(fn, title, topic, id)


def process_pdf(pdf_path: Path, title: str, topic: str, id: str):
    """
    –í—ã–∑—ã–≤–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É pdf –∏ –∑–∞—Ç–µ–º —É–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –±–ª–æ–∫–∏ –¥–≤—É—Ö —Ä–∞–∑–¥–µ–ª–æ–≤.
    """
    try:
        data = parse(pdf_path)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–±–æ—Ä–µ —Ñ–∞–π–ª–∞: {e}")
        traceback.print_exc()
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å")
        return

    save_json(data, title, topic, id)

    try:
        pdf_path.unlink()
        print(f"[üóë] –£–¥–∞–ª—ë–Ω PDF: {pdf_path.name}")
    except Exception as e:
        print(f"[!] –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {pdf_path}: {e}")
    return data


def save_json(data, title: str, topic: str, id: str):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –≤–∏–¥–µ json –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
    """
    if not data:
        return

    titles, intro_pages, review_pages = data

    if not intro_pages:
        return

    fnj = OUT / f"{get_md5_hash(title)}.json"
    title, year = title[:-6], title[-6:]

    # –ï—Å–ª–∏ —É –Ω–∞—Å –µ—Å—Ç—å —Ä–∞–∑–¥–µ–ª "–û–±–∑–æ—Ä" –∏–ª–∏ –ø–æ—Ö–æ–∂–∏–π
    if review_pages:
        result = {
            'id': id,
            '–∑–∞–≥–æ–ª–æ–≤–æ–∫': title,
            '–≥–æ–¥': year,
            '—Ç–µ–º–∞': topic,
            titles[0]: intro_pages,
            titles[1]: review_pages
        }
    # –ï—Å–ª–∏ —É –Ω–∞—Å –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ "–í–≤–µ–¥–µ–Ω–∏–µ"
    else:
        result = {
            'id': id,
            '–∑–∞–≥–æ–ª–æ–≤–æ–∫': title,
            '–≥–æ–¥': year,
            '—Ç–µ–º–∞': topic,
            titles[0]: intro_pages
        }

    with open(fnj, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    return


def get_md5_hash(header: str) -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç MD5-—Ö—ç—à –æ—Ç —Å—Ç—Ä–æ–∫–∏.
    –†–µ–∑—É–ª—å—Ç–∞—Ç –º–µ–∂–¥—É –∑–∞–ø—É—Å–∫–∞–º–∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ç–æ—Ä–∞ –±—É–¥–µ—Ç –æ–¥–∏–Ω–∞–∫–æ–≤.
    """
    # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Å—Ç—Ä–æ–∫—É –≤ –±–∞–π—Ç—ã. –ö–æ–¥–∏—Ä—É–µ–º –≤ UTF-8.
    header_bytes = header.encode('utf-8')
    # –í—ã—á–∏—Å–ª—è–µ–º MD5
    md5_obj = hashlib.md5(header_bytes)
    # –ü–æ–ª—É—á–∞–µ–º —à–µ—Å—Ç–Ω–∞–¥—Ü–∞—Ç–µ—Ä–∏—á–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
    return md5_obj.hexdigest()


def main():
    # —Å–µ—Å—Å–∏—è requests –¥–ª—è PDF
    sess = requests.Session()
    sess.headers.update(HEAD)

    # selenium
    opts = Options()
    opts.add_argument("--headless")
    opts.add_argument("--disable-gpu")
    driver = webdriver.Chrome(options=opts)
    opts.add_argument("--window-size=1920,1080")
    driver.get(URL)

    # –ø—Ä–∏–Ω—è—Ç—å –∫—É–∫–∏, –µ—Å–ª–∏ –µ—Å—Ç—å
    try:
        btn = WebDriverWait(driver, 3).until(
            EC.element_to_be_clickable((By.CSS_SELECTOR, "button.acceptcookies"))
        )
        btn.click()
        time.sleep(1)
    except:
        pass

    page = 1
    while True:
        print(f"\n=== –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page} ===")
        page_url = f"{BASE}/theses.html?page={page}&{PARAMS}"
        try:
            driver.get(page_url)
            # –∂–¥—ë–º, –ø–æ–∫–∞ –≤ #ThesisList –ø–æ—è–≤–∏—Ç—Å—è —Ö–æ—Ç—è –±—ã –æ–¥–Ω–∞ —Ä–∞–±–æ—Ç–∞
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "#ThesisList > div"))
            )
            # –≤—Å–µ –ø—Ä—è–º—ã–µ –¥–æ—á–∫–∏ #ThesisList ‚Äî –ø–æ –Ω–∏–º –∏ –ø—Ä–æ–π–¥—ë–º
            entries = driver.find_elements(By.CSS_SELECTOR, "#ThesisList > div")
            if not entries:
                print("[!] –ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –≤ #ThesisList, –≤—ã—Ö–æ–¥–∏–º.")
                break

            for entry in entries:
                # –∏—â–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –ø–æ full XPath (–º–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤ –∫–æ–¥–µ —Å–∞–π—Ç–∞), –Ω–æ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ entry
                try:
                    title_el = entry.find_element(
                        By.XPATH,
                        ".//div/div/div[1]/h6/strong"
                    )
                    title = title_el.text.strip()
                except:
                    print("[!] –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤ entry, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                    continue

                # –∏—â–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ pdf –ø–æ full XPath –≤–Ω—É—Ç—Ä–∏ entry
                try:
                    a = entry.find_element(
                        By.XPATH,
                        ".//div/div/div[2]/a[1]"

                    )
                    href = a.get_attribute("href")
                    if not href.startswith("http"):
                        href = BASE + href
                except:
                    print(f"[!] PDF –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è ¬´{title}¬ª")
                    continue

                # –∏—â–µ–º —Ç–µ–º—É (–Ω–∞–∑–≤–∞–Ω–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è/–∫–∞—Ñ–µ–¥—Ä—ã) –ø–æ full XPath –≤–Ω—É—Ç—Ä–∏ entry
                try:
                    topic_el = entry.find_element(
                        By.XPATH,
                        ".//div[2]/p[3]/i"
                    )
                    topic = topic_el.text.strip()
                except:
                    print(f"[!] Topic –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è ¬´{title}¬ª")
                    topic = None

                # —Å–∫–∞—á–∏–≤–∞–µ–º pdf
                download(sess, href, title, topic)

        # –ü–æ—Å–∫–æ–ª—å–∫—É —Å–∞–π—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–µ —Å–æ–≤—Å–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ (–Ω–∞ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å 404),
        # –±—É–¥–µ–º –∏—Ö –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å (–Ω–∞–π–¥–µ–º —ç—Ç–∏ —Ñ–∞–π–ª—ã –¥–∞–ª–µ–µ, –Ω–æ –¥—Ä—É–≥–∏–º —Å–ø–æ—Å–æ–±–æ–º):
        except (TimeoutException, WebDriverException) as e:
            print(f"[!] –û—à–∏–±–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page}: {e}. –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–π.")

        finally:
            page += 1
            time.sleep(2)

    driver.quit()


if __name__ == "__main__":
    main()
