{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12129990,"sourceType":"datasetVersion","datasetId":7633882}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!curl -fsSL https://ollama.com/install.sh | sh\nimport subprocess\nprocess = subprocess.Popen(\"ollama serve\", shell=True)\n!ollama pull llama3\n!pip install ollama\nimport ollama","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#HSE\n\n# # Файл с именами файлов, которые уже обработаны\n# PROCESSED_DIR = \"/kaggle/input/dataset-real-diploma/processed-json-hse\"\n# # Директория с json после парсера и обработки\n# INPUT_DIR = \"/kaggle/input/dataset-real-diploma/dataset-hse/dataset-hse\"\n# # Куда сохранять результат\n# OUTPUT_DIR = \"./processed\"\n# EXCLUDE_KEYS = {'заголовок', 'год', 'тема', 'код_темы'}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# SPBU\n\n# Файл с именами файлов, которые уже обработаны\nPROCESSED_DIR = \"/kaggle/input/dataset-real-diploma/processed-json-hse\"\n# Директория с json после парсера и обработки\nINPUT_DIR = \"/kaggle/input/dataset-real-diploma/dataset-spbu/dataset-spbu\"\n# Куда сохранять результат\nOUTPUT_DIR = \"./processed\"\nEXCLUDE_KEYS = {'id','заголовок', 'год', 'тема'}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"! ollama pull qwen2.5vl:7b","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\ndef load_json_list(json_path: str):\n    \"\"\"\n    Читает json-файл и возвращает соответствующий python-список.\n    \"\"\"\n    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n        \n    if not isinstance(data, list):\n        raise ValueError(f\"Ожидался список, а в файле {json_path} — {type(data).__name__}\")\n    return data\n\ndata_processed = load_json_list(PROCESSED_DIR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T11:17:18.635043Z","iopub.execute_input":"2025-06-11T11:17:18.635255Z","iopub.status.idle":"2025-06-11T11:17:18.643004Z","shell.execute_reply.started":"2025-06-11T11:17:18.635230Z","shell.execute_reply":"2025-06-11T11:17:18.642264Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import glob\nimport json\nimport os\nimport re\n\nprompt = \"Продолжи следующий текст до целого абзаца: \"\n\ndef get_first_sentence(text: str) -> str:\n    \"\"\"\n    Берём первое предложение из текста.\n    \"\"\"\n    match = re.match(r\"(.+?[\\.!?])\", text.strip(), flags=re.DOTALL)\n    return match.group(1) if match else text.strip()\n\ndef generate_text_for_prompt(prompt: str, sentence) -> str:\n    \"\"\"\n    Генерируем текст по промпту.\n    \"\"\"\n    response = ollama.chat(model='qwen2.5vl:7b', messages=[\n  {\n    'role': 'user',\n    'content': prompt + '\"' + sentence + '\"',\n  },\n    ])\n    return(response['message']['content'])\n\n\ndef process_file(path: str):\n    with open(path, \"r\", encoding=\"utf-8\") as rf:\n        data = json.load(rf)\n\n    new_data = {}\n    # Сначала копируем «исключённые» ключи\n    for key in EXCLUDE_KEYS:\n        if key in data:\n            new_data[key] = data[key]\n\n    # Обрабатываем все остальные ключи\n    for key, value in data.items():\n        if key in EXCLUDE_KEYS:\n            continue\n        if not isinstance(value, list):\n            new_data[key] = value\n            continue\n\n        new_list = []\n        for real_text in value:\n            sentence = get_first_sentence(real_text)\n\n            generated = generate_text_for_prompt(prompt, sentence)\n\n            new_list.append({\n                \"real_text\": real_text,\n                \"generated_text\": generated\n            })\n\n        new_data[key] = new_list\n\n    # Сохраняем результат\n    os.makedirs(OUTPUT_DIR, exist_ok=True)\n    fname = os.path.basename(path)\n    out_path = os.path.join(OUTPUT_DIR, fname)\n    with open(out_path, \"w\", encoding=\"utf-8\") as wf:\n        json.dump(new_data, wf, ensure_ascii=False, indent=2)\n\ndef main():\n    json_paths = glob.glob(os.path.join(INPUT_DIR, \"*.json\"))\n    for p in json_paths:\n        fname = os.path.basename(p) \n        if fname in data_processed:\n            print (f\"Пропускаем {fname}, уже обработан\")\n            continue\n        print(f\"Обрабатываем {p} ...\")\n        process_file(p)\n    print(\"Готово. Все файлы в\", OUTPUT_DIR)\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}